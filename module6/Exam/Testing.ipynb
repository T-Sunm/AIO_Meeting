{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomNetwork(\n",
      "  (main_branch): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (skip_connection): Sequential(\n",
      "    (0): Conv2d(3, 3, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n",
      "Output shape: torch.Size([1, 3, 29, 29])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # Nhánh chính\n",
    "        self.main_branch = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32,\n",
    "                      kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32,\n",
    "                      kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=3,\n",
    "                      kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Nhánh Skip Connection\n",
    "        self.skip_connection = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=3,\n",
    "                      kernel_size=7, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Tính toán nhánh chính\n",
    "        main_out = self.main_branch(x)\n",
    "\n",
    "        # Tính toán nhánh Skip Connection\n",
    "        skip_out = self.skip_connection(x)\n",
    "\n",
    "        # Kết hợp hai nhánh\n",
    "        output = main_out + skip_out\n",
    "        return output\n",
    "\n",
    "\n",
    "# Kiểm tra mô hình\n",
    "model = CustomNetwork()\n",
    "print(model)\n",
    "\n",
    "# Input tensor\n",
    "input_tensor = torch.randn(1, 3, 64, 64)  # Shape [1, 3, 64, 64]\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " tensor([[0.4621, 0.9118, 0.9888]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the RNN with hardcoded weights\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "\n",
    "        # Hardcoded weights for hidden state update\n",
    "        self.Whh = torch.tensor([[0.0, -1.0],\n",
    "                                 # Shape: (2, 2)\n",
    "                                 [0.0, -1.0]], dtype=torch.float32)\n",
    "        self.bhh = torch.tensor(\n",
    "            [1.0, 1.0], dtype=torch.float32)        # Shape: (2,)\n",
    "\n",
    "        # Hardcoded weights for input to hidden state\n",
    "        self.Wxh = torch.tensor([[-1.0, 0.0, 0.5],\n",
    "                                 # Shape: (2, 3)\n",
    "                                 [1.0, 0.0, -0.5]], dtype=torch.float32)\n",
    "        self.bxh = torch.tensor(\n",
    "            [1.0, 1.0], dtype=torch.float32)           # Shape: (2,)\n",
    "\n",
    "        # Hardcoded weights for hidden state to output\n",
    "        self.Who = torch.tensor(\n",
    "            [[0.0, 1.0]], dtype=torch.float32)  # Shape: (1, 2)\n",
    "        self.bho = torch.tensor(\n",
    "            [0.0], dtype=torch.float32)         # Shape: (1,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input sequence of shape (batch_size, seq_len, input_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        # Initial hidden state (h_0) with size (batch_size, hidden_size)\n",
    "        h_t = torch.zeros(batch_size, 2)\n",
    "        outputs = []\n",
    "\n",
    "        # Iterate through the sequence\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]  # Current input (shape: batch_size, input_size)\n",
    "\n",
    "            # Compute the hidden state: h_t = tanh(Whh @ h_{t-1} + Wxh @ x_t + b)\n",
    "            h_t = torch.tanh(\n",
    "                torch.matmul(h_t, self.Whh.T) +  # Hidden to hidden\n",
    "                torch.matmul(x_t, self.Wxh.T) +  # Input to hidden\n",
    "                self.bxh  # Bias\n",
    "            )\n",
    "\n",
    "            # Compute the output: y_t = Who @ h_t + bho\n",
    "            y_t = torch.matmul(h_t, self.Who.T) + self.bho\n",
    "            outputs.append(y_t)\n",
    "\n",
    "        # Concatenate outputs along the sequence dimension\n",
    "        outputs = torch.cat(outputs, dim=1)  # Shape: (batch_size, seq_len)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = CustomRNN()\n",
    "\n",
    "# Input sequence (batch_size=1, seq_len=3, input_size=3)\n",
    "input_sequence = torch.tensor([[[1.0, 2.0, 3.0],\n",
    "                                [4.0, 5.0, 6.0],\n",
    "                                [7.0, 8.0, 9.0]]], dtype=torch.float32)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_sequence)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output (after Fully Connected Layer):\n",
      " tensor([[0.4621, 0.9118, 0.9888]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the RNN with hardcoded weights\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "\n",
    "        # Hardcoded weights for hidden state update\n",
    "        self.Whh = torch.tensor([[0.0, -1.0],\n",
    "                                 # Shape: (2, 2)\n",
    "                                 [0.0, -1.0]], dtype=torch.float32)\n",
    "        self.bhh = torch.tensor(\n",
    "            [1.0, 1.0], dtype=torch.float32)        # Shape: (2,)\n",
    "\n",
    "        # Hardcoded weights for input to hidden state\n",
    "        self.Wxh = torch.tensor([[-1.0, 0.0, 0.5],\n",
    "                                 # Shape: (2, 3)\n",
    "                                 [1.0, 0.0, -0.5]], dtype=torch.float32)\n",
    "        self.bxh = torch.tensor(\n",
    "            [1.0, 1.0], dtype=torch.float32)           # Shape: (2,)\n",
    "\n",
    "        # Fully connected layer (Who)\n",
    "        self.Who = torch.tensor(\n",
    "            [[0.0, 1.0]], dtype=torch.float32)  # Shape: (1, 2)\n",
    "        self.bho = torch.tensor(\n",
    "            [0.0], dtype=torch.float32)         # Shape: (1,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input sequence of shape (batch_size, seq_len, input_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        # Initial hidden state (h_0) with size (batch_size, hidden_size)\n",
    "        h_t = torch.zeros(batch_size, 2)\n",
    "        outputs = []\n",
    "\n",
    "        # Iterate through the sequence\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]  # Input at time step t\n",
    "\n",
    "            # Compute the hidden state: h_t = tanh(Whh @ h_{t-1} + Wxh @ x_t + b)\n",
    "            h_t = torch.tanh(\n",
    "                torch.matmul(h_t, self.Whh.T) +  # Hidden to hidden\n",
    "                torch.matmul(x_t, self.Wxh.T) +  # Input to hidden\n",
    "                self.bxh  # Bias\n",
    "            )\n",
    "\n",
    "            # Compute the output: y_t = Who @ h_t + bho\n",
    "            y_t = torch.matmul(h_t, self.Who.T) + self.bho\n",
    "            outputs.append(y_t)\n",
    "\n",
    "        # Concatenate outputs along the sequence dimension\n",
    "        outputs = torch.cat(outputs, dim=1)  # Shape: (batch_size, seq_len)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = CustomRNN()\n",
    "\n",
    "# Input sequence (batch_size=1, seq_len=3, input_size=3)\n",
    "input_sequence = torch.tensor([[[1.0, 2.0, 3.0],\n",
    "                                [4.0, 5.0, 6.0],\n",
    "                                [7.0, 8.0, 9.0]]], dtype=torch.float32)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_sequence)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output (after Fully Connected Layer):\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding:\n",
      " tensor([[1.5000, 0.5000, 0.5000, 1.5000],\n",
      "        [1.5000, 1.0000, 1.0000, 1.5000],\n",
      "        [1.0000, 0.7500, 0.7500, 1.0000]])\n",
      "\n",
      "Positional Encoding:\n",
      " tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "        [ 0.9093, -0.4161,  0.0200,  0.9998]])\n",
      "\n",
      "Final Embedding (Word + Positional):\n",
      " tensor([[1.5000, 1.5000, 0.5000, 2.5000],\n",
      "        [2.3000, 1.5000, 1.0000, 2.5000],\n",
      "        [1.9000, 0.3000, 0.8000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# Hàm tính Positional Encoding\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Tính Positional Encoding cho chuỗi đầu vào.\n",
    "    \n",
    "    Args:\n",
    "        seq_len (int): Độ dài chuỗi (sequence length).\n",
    "        d_model (int): Kích thước embedding.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Tensor Positional Encoding với shape (seq_len, d_model).\n",
    "    \"\"\"\n",
    "    # Tạo ma trận PE với shape (seq_len, d_model)\n",
    "    PE = torch.zeros(seq_len, d_model)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(\n",
    "        1)  # Shape: (seq_len, 1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float(\n",
    "    ) * (-math.log(10000.0) / d_model))  # Shape: (d_model/2)\n",
    "\n",
    "    # Áp dụng công thức sin cho các chỉ số chẵn\n",
    "    PE[:, 0::2] = torch.sin(position * div_term)\n",
    "    # Áp dụng công thức cos cho các chỉ số lẻ\n",
    "    PE[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    return PE\n",
    "\n",
    "\n",
    "# Tạo Word Embedding\n",
    "word_embedding = torch.tensor([\n",
    "    [1.5, 0.5, 0.5, 1.5],\n",
    "    [1.5, 1.0, 1.0, 1.5],\n",
    "    [1.0, 0.75, 0.75, 1.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Tính Positional Encoding\n",
    "seq_len, d_model = word_embedding.shape\n",
    "positional_embedding = positional_encoding(seq_len, d_model)\n",
    "\n",
    "# Tổng hợp Word Embedding và Positional Encoding để tính Final Embedding\n",
    "final_embedding = word_embedding + positional_embedding\n",
    "final_embedding = torch.round(final_embedding * 10) / 10\n",
    "# Hiển thị kết quả\n",
    "print(\"Word Embedding:\\n\", word_embedding)\n",
    "print(\"\\nPositional Encoding:\\n\", positional_embedding)\n",
    "print(\"\\nFinal Embedding (Word + Positional):\\n\", final_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Matrix (Q):\n",
      " tensor([[1.7000, 2.5000, 4.8000, 1.8000],\n",
      "        [1.9000, 2.9000, 5.7000, 2.2000],\n",
      "        [1.4000, 2.1000, 4.0000, 1.6000]])\n",
      "\n",
      "Key Matrix (K):\n",
      " tensor([[4.6000, 3.2000, 2.7000, 2.2000],\n",
      "        [5.2000, 3.5000, 3.4000, 2.4000],\n",
      "        [3.9000, 2.7000, 2.3000, 1.8000]])\n",
      "\n",
      "Value Matrix (V):\n",
      " tensor([[1.8000, 1.8000, 1.8000, 1.9000],\n",
      "        [1.8000, 2.0000, 2.2000, 2.4000],\n",
      "        [1.2000, 1.5000, 1.8000, 2.1000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Tạo ma trận Query Weight, Query Bias, và tính Query Matrix\n",
    "query_weight = torch.tensor([\n",
    "    [0.1, 0.2, 0.6, 0.4],\n",
    "    [0.2, 0.3, 0.7, 0.3],\n",
    "    [0.3, 0.4, 0.8, 0.2],\n",
    "    [0.4, 0.5, 0.9, 0.1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Tạo ma trận Query Bias (b)\n",
    "query_bias = torch.tensor([\n",
    "    [0.1, 0.3, 0.2, 0.4],\n",
    "    [0.1, 0.3, 0.2, 0.4],\n",
    "    [0.1, 0.3, 0.2, 0.4]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "input_matrix = final_embedding\n",
    "\n",
    "query_matrix = torch.matmul(input_matrix, query_weight) + query_bias\n",
    "# Làm tròn lên chữ số thập phân thứ 1\n",
    "query_matrix = torch.round(query_matrix * 10) / 10\n",
    "print(\"Query Matrix (Q):\\n\", query_matrix)\n",
    "\n",
    "# Tạo ma trận Key Weight, Key Bias, và tính Key Matrix\n",
    "key_weight = torch.tensor([\n",
    "    [0.2, 0.1, 0.3, 0.0],\n",
    "    [0.4, 0.3, 0.6, 0.2],\n",
    "    [0.8, 0.5, 0.9, 0.4],\n",
    "    [1.0, 0.7, 0.2, 0.6]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Tạo ma trận Key Bias (b)\n",
    "key_bias = torch.tensor([\n",
    "    [0.8, 0.6, 0.4, 0.2],\n",
    "    [0.8, 0.6, 0.4, 0.2],\n",
    "    [0.8, 0.6, 0.4, 0.2]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "key_matrix = torch.matmul(input_matrix, key_weight) + key_bias\n",
    "# Làm tròn lên chữ số thập phân thứ 1\n",
    "key_matrix = torch.round(key_matrix * 10) / 10\n",
    "print(\"\\nKey Matrix (K):\\n\", key_matrix)\n",
    "\n",
    "# Tạo ma trận Value Weight, Value Bias, và tính Value Matrix\n",
    "value_weight = torch.tensor([\n",
    "    [0.05, 0.15, 0.25, 0.35],\n",
    "    [0.35, 0.25, 0.15, 0.05],\n",
    "    [0.05, 0.15, 0.25, 0.35],\n",
    "    [0.35, 0.25, 0.15, 0.05]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Tạo ma trận Value Bias (b)\n",
    "value_bias = torch.tensor([\n",
    "    [0.25, 0.5, 0.75, 1.0],\n",
    "    [0.25, 0.5, 0.75, 1.0],\n",
    "    [0.25, 0.5, 0.75, 1.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "value_matrix = torch.matmul(input_matrix, value_weight) + value_bias\n",
    "# Làm tròn lên chữ số thập phân thứ 1\n",
    "value_matrix = torch.round(value_matrix * 10) / 10\n",
    "print(\"\\nValue Matrix (V):\\n\", value_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.4000, 19.1000, 13.8000],\n",
       "        [19.1000, 22.3000, 16.2000],\n",
       "        [13.7000, 16.0000, 11.6000]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk = key_matrix.shape[1]\n",
    "attention_scores = torch.matmul(\n",
    "    query_matrix, key_matrix.T) / torch.sqrt(torch.tensor(dk, dtype=torch.float32))\n",
    "attention_scores = torch.round(attention_scores * 10) / 10\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask Matrix:\n",
      " tensor([[0., -inf, -inf],\n",
      "        [0., 0., -inf],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Tạo ma trận Mask\n",
    "mask = torch.tensor([\n",
    "    [0, -float('inf'), -float('inf')],\n",
    "    [0, 0, -float('inf')],\n",
    "    [0, 0, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(\"Mask Matrix:\\n\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8000, 1.8000, 1.8000, 1.9000],\n",
       "        [1.8000, 2.0000, 2.2000, 2.4000],\n",
       "        [1.2000, 1.5000, 1.8000, 2.1000]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.4000,    -inf,    -inf],\n",
       "        [19.1000, 22.3000,    -inf],\n",
       "        [13.7000, 16.0000, 11.6000]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8000, 1.8000, 1.8000, 1.9000],\n",
       "        [1.8000, 2.0000, 2.2000, 2.4000],\n",
       "        [1.8000, 2.0000, 2.2000, 2.4000]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_with_mask = attention_scores + mask\n",
    "attention_scores_mask = F.softmax(scores_with_mask, dim=-1)\n",
    "attention_scores_mask = torch.matmul(attention_scores_mask, value_matrix)\n",
    "attention_scores_mask = torch.round(attention_scores_mask * 10) / 10\n",
    "attention_scores_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores_mask = torch.tensor([[1.8000, 1.8000, 1.8000, 1.9000],\n",
    "                                      [1.8000, 2.0000, 2.2000, 2.4000],\n",
    "                                      [1.8000, 2.0000, 2.2000, 2.4000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0337, -0.0337, -1.3798,  1.4471],\n",
       "        [ 0.2694, -0.6543, -1.1162,  1.5011],\n",
       "        [ 0.4472, -1.3416, -0.4472,  1.3416]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_input = attention_scores_mask + final_embedding\n",
    "layer_norm = nn.LayerNorm(normalized_shape=combined_input.size(\n",
    "    1), eps=0)\n",
    "\n",
    "# Thủ công set γ = 1 và β = 0\n",
    "with torch.no_grad():\n",
    "    layer_norm.weight.fill_(1.0)  # γ = 1\n",
    "    layer_norm.bias.fill_(0.0)   # β = 0\n",
    "output = layer_norm(combined_input)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIOEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
