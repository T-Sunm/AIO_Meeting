{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 6])\n",
      "Output shape: torch.Size([2, 2])\n",
      "Output: tensor([[ 0.5907, -0.2944],\n",
      "        [-0.4201,  0.2187]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyConv1DModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, out_channels=1, kernel_size=2, fc_out_dim=2):\n",
    "        super(MyConv1DModel, self).__init__()\n",
    "\n",
    "        # (A) Embedding layer\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "        custom_weights = torch.tensor([\n",
    "            [0.26, -1.31],  # 0  <unk>\n",
    "            [0.72, 0.43],  # 1  <pad>\n",
    "            [-0.67, 0.61],  # 2  more\n",
    "            [0.50, 0.50],  # 3  you\n",
    "            [-0.26, -0.10],  # 4  come\n",
    "            [1.29, 1.25],  # 5  get\n",
    "            [1.95, 1.18],  # 6  low\n",
    "            [-1.44, -1.89],  # 7  lucky\n",
    "            [-0.20, 0.88],  # 8  score\n",
    "            [-0.39, 1.07],  # 9  study\n",
    "            [0.32, -0.05],  # 10 the \n",
    "            [0.59, -0.98],  # 11 to\n",
    "        ], dtype=torch.float)\n",
    "\n",
    "\n",
    "        # G√°n cho embedding layer:\n",
    "        with torch.no_grad():\n",
    "            self.embedding.weight.copy_(custom_weights)\n",
    "\n",
    "        # (B) Conv1d: in_channels=2, out_channels=1, kernel_size=2\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=embedding_dim,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "\n",
    "        # (C) FC (6 -> 2) v√¨ sau conv1d ta c√≥ (batch, 1, 6) => flatten => 6\n",
    "        self.fc = nn.Linear(5, fc_out_dim)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        #  G√ÅN TR·ªåNG S·ªê TH·ª¶ C√îNG THEO H√åNH V·∫º\n",
    "        # --------------------------------------------------------\n",
    "        with torch.no_grad():\n",
    "            # 1) Conv1d weight & bias\n",
    "            # shape = (1, 2, 2)\n",
    "            custom_conv_weight = torch.tensor([[[0.33, -0.26],\n",
    "                                                [0.38, -0.46]]],\n",
    "                                              dtype=torch.float)\n",
    "            custom_conv_bias = torch.tensor([-0.30], dtype=torch.float)\n",
    "\n",
    "            self.conv1d.weight.copy_(custom_conv_weight)\n",
    "            self.conv1d.bias.copy_(custom_conv_bias)\n",
    "\n",
    "            # 2) FC weight & bias\n",
    "            # shape(fc.weight) = (2, 6), shape(fc.bias) = (2,)\n",
    "            custom_fc_weight = torch.tensor([\n",
    "                [0.40, -0.06, -0.44, -0.10, 0.43,],  # node 0\n",
    "                [-0.19, 0.28, -0.04, -0.01, 0.23,],  # node 1\n",
    "            ], dtype=torch.float)\n",
    "            custom_fc_bias = torch.tensor([0.18, 0.18], dtype=torch.float)\n",
    "\n",
    "            self.fc.weight.copy_(custom_fc_weight)\n",
    "            self.fc.bias.copy_(custom_fc_bias)\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (batch_size, seq_len)\n",
    "        # (1) Embedding => (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # (2) Permute => (batch_size, embedding_dim, seq_len)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # (3) Conv1d => (batch_size, out_channels=1, new_length=6)\n",
    "        x = self.conv1d(x)\n",
    "        \n",
    "        x = torch.tensor([[[0.5900, -1.6224, 0.5405, -1.2632, 0.4391]],\n",
    "                         [[-0.68, -0.13, 0.95, -1.38, -0.13]]])\n",
    "\n",
    "        # (4) Flatten => (batch_size, 6)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # (5) FC => (batch_size, fc_out_dim=2)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "# =====================================\n",
    "input_vector_1 = torch.tensor([3, 0, 5, 10, 6, 8], dtype=torch.long)\n",
    "input_vector_2 = torch.tensor([2, 9, 2, 7, 4, 1], dtype=torch.long)\n",
    "X = torch.stack([input_vector_1, input_vector_2], dim=0)\n",
    "\n",
    "print(\"Input shape:\", X.shape)  # (2, 7)\n",
    "\n",
    "# =====================================\n",
    "# Kh·ªüi t·∫°o v√† ch·∫°y th·ª≠ m√¥ h√¨nh\n",
    "# =====================================\n",
    "vocab_size = 12\n",
    "embedding_dim = 2\n",
    "\n",
    "model = MyConv1DModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    out_channels=1,\n",
    "    kernel_size=2,\n",
    "    fc_out_dim=2\n",
    ")\n",
    "\n",
    "output = model(X)\n",
    "print(\"Output shape:\", output.shape)  # (2, 2)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 6, 4])\n",
      "Output logits:\n",
      " tensor([[[-1.7674, -1.1379, -0.9054, -2.2598],\n",
      "         [-1.6684, -1.0048, -1.1336, -2.0920],\n",
      "         [-1.9867, -1.0435, -1.0086, -1.9246],\n",
      "         [-1.9444, -1.0939, -0.9340, -2.0478],\n",
      "         [-1.7223, -1.0941, -0.9748, -2.2142],\n",
      "         [-1.7620, -1.0440, -1.0412, -2.0937]],\n",
      "\n",
      "        [[-1.7695, -1.1969, -0.8359, -2.3648],\n",
      "         [-1.8412, -1.0429, -1.0275, -2.0324],\n",
      "         [-1.7695, -1.1969, -0.8359, -2.3648],\n",
      "         [-2.0036, -0.9812, -1.1247, -1.7984],\n",
      "         [-2.0313, -1.1137, -0.8974, -2.0185],\n",
      "         [-1.8774, -1.0375, -1.0308, -1.9955]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Predicted POS labels:\n",
      " tensor([[2, 1, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 1, 2, 2]])\n",
      "Loss: 1.480851650238037\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class POSTaggingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes=4):\n",
    "        super(POSTaggingModel, self).__init__()\n",
    "\n",
    "        # Embedding Layer (Chuy·ªÉn token -> vector)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        \n",
    "        custom_weights = torch.tensor([\n",
    "            [0.26, -1.31],  # 0  <unk>\n",
    "            [0.72, 0.43],  # 1  <pad>\n",
    "            [-0.67, 0.61],  # 2  more\n",
    "            [0.50, 0.50],  # 3  you\n",
    "            [-0.26, -0.10],  # 4  come\n",
    "            [1.29, 1.25],  # 5  get\n",
    "            [1.95, 1.18],  # 6  low\n",
    "            [-1.44, -1.89],  # 7  lucky\n",
    "            [-0.20, 0.88],  # 8  score\n",
    "            [-0.39, 1.07],  # 9  study\n",
    "            [0.32, -0.05],  # 10 the\n",
    "            [0.59, -0.98],  # 11 to\n",
    "        ], dtype=torch.float)\n",
    "        # G√°n cho embedding layer:\n",
    "        with torch.no_grad():\n",
    "            self.embedding.weight.copy_(custom_weights)\n",
    "        # Fully Connected Layer (Nh·∫≠n embedding, xu·∫•t ra 4 class)\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        #  G√ÅN TR·ªåNG S·ªê TH·ª¶ C√îNG THEO H√åNH V·∫º\n",
    "        # --------------------------------------------------------\n",
    "        with torch.no_grad():\n",
    "            # (A) Embedding tr·ªçng s·ªë (t·∫°o ng·∫´u nhi√™n ho·∫∑c load t·ª´ file pretrained n·∫øu c√≥)\n",
    "            # ·ªû ƒë√¢y m√¨nh ƒë·ªÉ random, b·∫°n c√≥ th·ªÉ thay b·∫±ng pretrained weights n·∫øu c·∫ßn\n",
    "            custom_embedding_weights = torch.rand(vocab_size, embedding_dim)\n",
    "            self.embedding.weight.copy_(custom_embedding_weights)\n",
    "\n",
    "            # (B) G√°n weight FC theo h√¨nh\n",
    "            custom_fc_weight = torch.tensor([\n",
    "                [0.3792, 0.4146],  # w0\n",
    "                [0.4638, -0.0273],  # w1\n",
    "                [-0.2622, 0.2486],  # w2\n",
    "                [0.5454, -0.3664],  # w3\n",
    "            ], dtype=torch.float)\n",
    "            self.fc.weight.copy_(custom_fc_weight)\n",
    "\n",
    "            # (C) G√°n bias FC theo h√¨nh\n",
    "            custom_fc_bias = torch.tensor(\n",
    "                [-0.62, 0.37, 0.57, -0.48], dtype=torch.float)\n",
    "            self.fc.bias.copy_(custom_fc_bias)\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. L·∫•y embedding cho t·ª´ng token\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # 2. Fully Connected Layer\n",
    "        x = self.fc(x)  # (batch_size, seq_len, num_classes)\n",
    "\n",
    "        # 3. Softmax ƒë·ªÉ chu·∫©n h√≥a x√°c su·∫•t\n",
    "        x = F.log_softmax(x, dim=-1)  # (batch_size, seq_len, num_classes)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# üîπ Kh·ªüi t·∫°o d·ªØ li·ªáu v·ªõi **6 tokens**\n",
    "# =====================================\n",
    "vocab_size = 12   # Gi·∫£ s·ª≠ vocab c√≥ 12 t·ª´ (gi·ªëng ·∫£nh)\n",
    "embedding_dim = 2  # Embedding c√≥ 2 chi·ªÅu\n",
    "num_classes = 4   # 4 class POS tagging\n",
    "\n",
    "# Gi·∫£ l·∫≠p batch g·ªìm 2 c√¢u, m·ªói c√¢u c√≥ 6 token\n",
    "input_vector_1 = torch.tensor([3, 0, 5, 10, 6, 8], dtype=torch.long)\n",
    "input_vector_2 = torch.tensor([2, 9, 2, 7, 4, 1], dtype=torch.long)\n",
    "X = torch.stack([input_vector_1, input_vector_2], dim=0)\n",
    "\n",
    "# Nh√£n th·ª±c t·∫ø (Target) cho 6 tokens\n",
    "target_labels = torch.tensor([\n",
    "    [0, 1, 2, 3, 0, 2],  # Nh√£n cho c√¢u 1\n",
    "    [2, 3, 1, 0, 1, 3]   # Nh√£n cho c√¢u 2\n",
    "], dtype=torch.long)\n",
    "\n",
    "# =====================================\n",
    "# üîπ Kh·ªüi t·∫°o v√† ch·∫°y th·ª≠ m√¥ h√¨nh\n",
    "# =====================================\n",
    "model = POSTaggingModel(vocab_size=vocab_size,\n",
    "                        embedding_dim=embedding_dim, num_classes=num_classes)\n",
    "\n",
    "# Forward Pass\n",
    "output = model(X)\n",
    "\n",
    "# L·∫•y nh√£n d·ª± ƒëo√°n (v·ªã tr√≠ c√≥ gi√° tr·ªã l·ªõn nh·∫•t tr√™n m·ªói token)\n",
    "predicted_labels = torch.argmax(output, dim=-1)  # (batch_size, seq_len)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(\"Output shape:\", output.shape)  # (batch_size=2, seq_len=6, num_classes)\n",
    "print(\"Output logits:\\n\", output)\n",
    "print(\"Predicted POS labels:\\n\", predicted_labels)\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# üîπ T√≠nh Loss\n",
    "# =====================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output.view(-1, num_classes), target_labels.view(-1))\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 6, 6])\n",
      "Output logits:\n",
      " tensor([[[-0.3919, -0.3171,  0.5895,  0.2339, -0.0224,  0.5002],\n",
      "         [-0.5143, -0.4956,  0.5719,  0.3103, -0.1750,  0.6450],\n",
      "         [-0.5387, -0.4904,  0.5579,  0.3242, -0.2123,  0.6228],\n",
      "         [-0.5538, -0.4547,  0.5486,  0.3258, -0.2327,  0.5626],\n",
      "         [-0.3275, -0.2517,  0.7864,  0.0566,  0.2581,  0.3234],\n",
      "         [-0.4223, -0.3168,  0.7369,  0.1264,  0.1089,  0.3569]],\n",
      "\n",
      "        [[-0.5719, -0.4025,  0.4513,  0.3914, -0.3493,  0.5418],\n",
      "         [-0.6746, -0.4111,  0.3775,  0.4682, -0.5260,  0.5037],\n",
      "         [-0.4611, -0.3578,  0.6707,  0.1934, -0.0034,  0.4261],\n",
      "         [-0.4833, -0.4829,  0.6137,  0.2698, -0.0993,  0.6272],\n",
      "         [-0.4782, -0.4153,  0.6553,  0.2215, -0.0423,  0.5031],\n",
      "         [-0.5417, -0.4476,  0.5670,  0.3078, -0.2006,  0.5509]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Predicted POS labels:\n",
      " tensor([[2, 5, 5, 5, 2, 2],\n",
      "        [5, 5, 2, 5, 2, 2]])\n",
      "Loss: 1.879526138305664\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNPOSModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size=3, num_classes=6):\n",
    "        super(RNNPOSModel, self).__init__()\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "        # RNN Cell\n",
    "        self.rnn = nn.RNNCell(input_size=embedding_dim,\n",
    "                              hidden_size=hidden_size)\n",
    "\n",
    "        # Fully Connected Layer (Hidden state ‚Üí POS class)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # üîπ G√ÅN TR·ªåNG S·ªê TH·ª¶ C√îNG THEO H√åNH V·∫º\n",
    "        # ----------------------------------------\n",
    "        with torch.no_grad():\n",
    "            # (A) G√°n tr·ªçng s·ªë Embedding (random)\n",
    "            custom_weights = torch.tensor([\n",
    "                [0.26, -1.31],  # 0  <unk>\n",
    "                [0.72, 0.43],  # 1  <pad>\n",
    "                [-0.67, 0.61],  # 2  at\n",
    "                [0.50, 0.50],  # 3  based\n",
    "                [-0.26, -0.10],  # 4  deepmind\n",
    "                [1.29, 1.25],  # 5  demis\n",
    "                [1.95, 1.18],  # 6  hassabis\n",
    "                [-1.44, -1.89],  # 7  in\n",
    "                [-0.20, 0.88],  # 8  is\n",
    "                [-0.39, 1.07],  # 9  nadella\n",
    "                [0.32, -0.05],  # 10 satya\n",
    "                [0.59, -0.98],  # 11 washington\n",
    "            ], dtype=torch.float)\n",
    "            self.embedding.weight.copy_(custom_weights)\n",
    "\n",
    "            # (B) G√°n tr·ªçng s·ªë RNN Cell\n",
    "            # W_in (3,2) - (hidden_size, embedding_dim)\n",
    "            custom_W_in = torch.tensor([\n",
    "                [-0.07, -0.31],\n",
    "                [-0.28, -0.19],\n",
    "                [-0.23, -0.15]\n",
    "            ], dtype=torch.float)\n",
    "            self.rnn.weight_ih.copy_(custom_W_in)\n",
    "\n",
    "            # b_in (3,)\n",
    "            custom_b_in = torch.tensor([-0.47, -0.47, 0.50], dtype=torch.float)\n",
    "            self.rnn.bias_ih.copy_(custom_b_in)\n",
    "\n",
    "            # W_hh (3,3) - (hidden_size, hidden_size)\n",
    "            custom_W_hh = torch.tensor([\n",
    "                [0.04, 0.37, 0.32],\n",
    "                [0.46, 0.54, -0.54],\n",
    "                [0.25, -0.02, 0.05]\n",
    "            ], dtype=torch.float)\n",
    "            self.rnn.weight_hh.copy_(custom_W_hh)\n",
    "\n",
    "            # b_hh (3,)\n",
    "            custom_b_hh = torch.tensor([0.42, -0.50, 0.41], dtype=torch.float)\n",
    "            self.rnn.bias_hh.copy_(custom_b_hh)\n",
    "\n",
    "            # (C) Tr·ªçng s·ªë Fully Connected (FC) - 6 class\n",
    "            # W_fc (6,3) - (num_classes, hidden_size)\n",
    "            custom_W_fc = torch.tensor([\n",
    "                [0.10, 0.53, 0.23],\n",
    "                [0.34, 0.32, -0.36],\n",
    "                [0.24, -0.35, 0.29],\n",
    "                [-0.28, 0.10, -0.18],\n",
    "                [0.39, 0.15, 0.49],\n",
    "                [-0.57, 0.35, 0.54]\n",
    "            ], dtype=torch.float)\n",
    "            self.fc.weight.copy_(custom_W_fc)\n",
    "\n",
    "            # b_fc (6,)\n",
    "            custom_b_fc = torch.tensor(\n",
    "                [-0.13, 0.20, 0.13, 0.42, -0.22, 0.37], dtype=torch.float)\n",
    "            self.fc.bias.copy_(custom_b_fc)\n",
    "        # ----------------------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # 2. RNN Cell x·ª≠ l√Ω t·ª´ng token\n",
    "        # Hidden state ban ƒë·∫ßu\n",
    "        h_t = torch.zeros(batch_size, self.rnn.hidden_size)\n",
    "        hidden_states = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h_t = self.rnn(x[:, t, :], h_t)  # (batch_size, hidden_dim)\n",
    "            # (batch_size, 1, hidden_dim)\n",
    "            hidden_states.append(h_t.unsqueeze(1))\n",
    "\n",
    "        # 3. G·ªôp t·∫•t c·∫£ hidden state l·∫°i\n",
    "        # (batch_size, seq_len, hidden_dim)\n",
    "        hidden_states = torch.cat(hidden_states, dim=1)\n",
    "\n",
    "        # 4. Fully Connected (FC) cho t·ª´ng token\n",
    "        out = self.fc(hidden_states)  # (batch_size, seq_len, num_classes)\n",
    "\n",
    "        # 5. Softmax\n",
    "        # out = F.log_softmax(out, dim=-1)  # (batch_size, seq_len, num_classes)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# üîπ Kh·ªüi t·∫°o d·ªØ li·ªáu v·ªõi **6 tokens**\n",
    "# =====================================\n",
    "vocab_size = 12   # Gi·∫£ s·ª≠ vocab c√≥ 12 t·ª´\n",
    "embedding_dim = 2  # Embedding c√≥ 2 chi·ªÅu\n",
    "hidden_size = 3    # Hidden state c·ªßa RNN\n",
    "num_classes = 6    # üîπ 6 class POS tagging\n",
    "\n",
    "# Gi·∫£ l·∫≠p batch g·ªìm 2 c√¢u, m·ªói c√¢u c√≥ 6 token\n",
    "input_vector_1 = torch.tensor([10, 9, 8, 3, 7, 11], dtype=torch.long)\n",
    "input_vector_2 = torch.tensor([5, 6, 0, 2, 4, 1], dtype=torch.long)\n",
    "X = torch.stack([input_vector_1, input_vector_2],\n",
    "                dim=0)  # (batch_size=2, seq_len=6)\n",
    "\n",
    "# Nh√£n th·ª±c t·∫ø (Target) c√≥ 6 nh√£n cho m·ªói token\n",
    "target_labels = torch.tensor([\n",
    "    [0, 1, 2, 3, 0, 2],  # Nh√£n cho c√¢u 1\n",
    "    [2, 3, 1, 0, 5, 4]   # Nh√£n cho c√¢u 2\n",
    "], dtype=torch.long)  # (batch_size=2, seq_len=6)\n",
    "\n",
    "# =====================================\n",
    "# üîπ Kh·ªüi t·∫°o v√† ch·∫°y th·ª≠ m√¥ h√¨nh\n",
    "# =====================================\n",
    "model = RNNPOSModel(vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
    "                    hidden_size=hidden_size, num_classes=num_classes)\n",
    "\n",
    "# Forward Pass\n",
    "output = model(X)  # (batch_size=2, seq_len=6, num_classes)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output logits:\\n\", output)\n",
    "\n",
    "# =====================================\n",
    "# üîπ L·∫•y nh√£n d·ª± ƒëo√°n\n",
    "# =====================================\n",
    "predicted_labels = torch.argmax(output, dim=-1)  # (batch_size, seq_len)\n",
    "print(\"Predicted POS labels:\\n\", predicted_labels)\n",
    "\n",
    "# =====================================\n",
    "# üîπ T√≠nh Loss\n",
    "# =====================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# (batch_size * seq_len, num_classes)\n",
    "loss = criterion(output.view(-1, num_classes), target_labels.view(-1))\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Tokens: ['how', 'are', 'aioers', '<sep>', 'aioers', 'are', 'friendly']\n",
      "Input IDs: [5, 4, 3, 2, 3, 4, 6]\n",
      "\n",
      "Final Input IDs: [5, 4, 3, 2, 3, 4, 6, 1, 1]\n",
      "New Start: -1\n",
      "New End: -1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1Ô∏è‚É£ B·ªô t·ª´ v·ª±ng (Vocabulary)\n",
    "vocab = {\n",
    "    \"<unk>\": 0, \"<pad>\": 1, \"<sep>\": 2,\n",
    "    \"aioers\": 3, \"are\": 4, \"how\": 5, \"friendly\": 6,\n",
    "    \"smart\": 7\n",
    "}\n",
    "\n",
    "# 2Ô∏è‚É£ D·ªØ li·ªáu ƒë·∫ßu v√†o\n",
    "question = [\"how\", \"are\", \"aioers\"]  # C√¢u h·ªèi\n",
    "context = [\"aioers\", \"are\", \"friendly\"]  # Ng·ªØ c·∫£nh\n",
    "answer = [\"very\", \"smart\"]  # C√¢u tr·∫£ l·ªùi\n",
    "\n",
    "# 3Ô∏è‚É£ Gh√©p l·∫°i th√†nh 1 c√¢u ho√†n ch·ªânh: <question> + sep + <context>\n",
    "input_tokens = question + [\"<sep>\"] + context\n",
    "print(\"Merged Tokens:\", input_tokens)\n",
    "\n",
    "# 4Ô∏è‚É£ Chuy·ªÉn th√†nh ch·ªâ s·ªë (tokenize & vectorize)\n",
    "# N·∫øu token kh√¥ng c√≥ trong vocab, thay b·∫±ng \"<unk>\" (0)\n",
    "input_ids = [vocab.get(token, vocab[\"<unk>\"]) for token in input_tokens]\n",
    "print(\"Input IDs:\", input_ids)\n",
    "\n",
    "# 5Ô∏è‚É£ Padding (ƒë·∫£m b·∫£o max_sequence_length = 9)\n",
    "max_sequence_length = 9\n",
    "input_ids += [vocab[\"<pad>\"]] * (max_sequence_length - len(input_ids))\n",
    "\n",
    "# 6Ô∏è‚É£ C·∫≠p nh·∫≠t Start & End (t√¨m v·ªã tr√≠ \"very smart\" trong c√¢u m·ªõi)\n",
    "# N·∫øu t·ª´ kh√¥ng c√≥ trong danh s√°ch th√¨ start/end s·∫Ω l√† -1\n",
    "try:\n",
    "    start_idx = input_tokens.index(answer[0])  # V·ªã tr√≠ m·ªõi c·ªßa \"very\"\n",
    "except ValueError:\n",
    "    start_idx = -1  # N·∫øu kh√¥ng t√¨m th·∫•y, g√°n -1\n",
    "\n",
    "try:\n",
    "    end_idx = input_tokens.index(answer[1])  # V·ªã tr√≠ m·ªõi c·ªßa \"smart\"\n",
    "except ValueError:\n",
    "    end_idx = -1  # N·∫øu kh√¥ng t√¨m th·∫•y, g√°n -1\n",
    "\n",
    "print(\"\\nFinal Input IDs:\", input_ids)\n",
    "print(\"New Start:\", start_idx)\n",
    "print(\"New End:\", end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2913, -0.5980, -0.7857],\n",
      "         [-0.1055, -0.4008, -0.2467],\n",
      "         [ 0.6169, -0.7608,  0.5012],\n",
      "         [ 0.9302, -0.8899,  0.9152]]], grad_fn=<TransposeBackward1>)\n",
      "Output shape: torch.Size([1, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# üîπ Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "        # G√°n tr·ªçng s·ªë Encoder RNN & Embedding\n",
    "        with torch.no_grad():\n",
    "            self.embedding.weight.copy_(torch.tensor([\n",
    "                [1.9, 0.0],  # <eos>  (Index 0)\n",
    "                [-2.1, 0.5],  # I      (Index 1)\n",
    "                [-0.8, -1.0],  # love   (Index 2)\n",
    "                [0.2, 0.6]   # you    (Index 3)\n",
    "            ], dtype=torch.float))\n",
    "\n",
    "            self.rnn.weight_ih_l0.copy_(torch.tensor(\n",
    "                [[0.5, 0.1], [-0.1, -0.2], [0.6, 0.2]]))\n",
    "            self.rnn.bias_ih_l0.copy_(torch.tensor([0.8, -0.3, 0.1]))\n",
    "\n",
    "            self.rnn.weight_hh_l0.copy_(torch.tensor(\n",
    "                [[0.1, 0.2, 0.2], [0.2, 0.4, -0.5], [-0.1, -0.5, 0.0]]))\n",
    "            self.rnn.bias_hh_l0.copy_(torch.tensor([-0.1, -0.5, 0.0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "# üîπ Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        # G√°n tr·ªçng s·ªë Decoder RNN & Embedding\n",
    "        with torch.no_grad():\n",
    "            self.embedding.weight.copy_(torch.tensor([\n",
    "                [-2.7, 1.4],  # <sos>  (Index 0)\n",
    "                [0.1, 0.0],  # <eos>  (Index 1)\n",
    "                [1.5, 0.2],  # t√¥i    (Index 2)\n",
    "                [2.2, -2.8],  # y√™u    (Index 3)\n",
    "                [-1.3, 0.1],  # b·∫°n    (Index 4)\n",
    "                [1.0, -0.5],  # anh    (Index 5)\n",
    "                [0.0, 0.0]   # em     (Index 6)\n",
    "            ], dtype=torch.float))\n",
    "\n",
    "            self.rnn.weight_ih_l0.copy_(torch.tensor(\n",
    "                [[-0.7, 0.4], [-0.3, 0.9], [0.6, -0.9]]))\n",
    "            self.rnn.bias_ih_l0.copy_(torch.tensor([0.0, 1.0, 1.1]))\n",
    "\n",
    "            self.rnn.weight_hh_l0.copy_(torch.tensor(\n",
    "                [[-0.1, -0.5, 0.8], [0.6, 0.0, -0.3], [-1.2, 0.0, 0.0]]))\n",
    "            self.rnn.bias_hh_l0.copy_(torch.tensor([-0.1, 0.5, 0.6]))\n",
    "\n",
    "            # G√°n tr·ªçng s·ªë Fully Connected\n",
    "            self.fc.weight.copy_(torch.tensor([\n",
    "                [0.2, -0.9, -0.4], [0.7, 0.7, 0.9], [0.7, 0.9, -1.4],\n",
    "                [-1.3, 1.2, 0.7], [-1.2, -1.3, 1.0], [0.4, -1.1, -0.7],\n",
    "                [-0.3, -0.6, -1.0]\n",
    "            ]))\n",
    "\n",
    "            self.fc.bias.copy_(torch.tensor(\n",
    "                [-1.1, 0.6, 0.5, 0.4, 0.4, -1.0, 0.0]))\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).unsqueeze(1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc(output.squeeze(1))\n",
    "        return prediction, hidden\n",
    "\n",
    "# üîπ Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size)\n",
    "\n",
    "        _, hidden = self.encoder(src)\n",
    "        print(_)\n",
    "        dec_input = trg[:, 0]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(dec_input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            dec_input = trg[:, t] if torch.rand(\n",
    "                1).item() < teacher_forcing_ratio else output.argmax(1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# üîπ Kh·ªüi t·∫°o m√¥ h√¨nh & D·ªØ li·ªáu\n",
    "# =====================================\n",
    "vocab_size_en = 4  # S·ªë t·ª´ trong vocab ti·∫øng Anh\n",
    "vocab_size_vi = 7  # S·ªë t·ª´ trong vocab ti·∫øng Vi·ªát\n",
    "embedding_dim = 2\n",
    "hidden_size = 3\n",
    "\n",
    "encoder = Encoder(vocab_size_en, embedding_dim, hidden_size)\n",
    "decoder = Decoder(vocab_size_vi, embedding_dim, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# üîπ C√¢u ti·∫øng Anh: \"I love you <eos>\"\n",
    "input_en = torch.tensor([[1, 2, 3, 0]], dtype=torch.long)  # Batch size = 1\n",
    "# üîπ C√¢u ti·∫øng Vi·ªát: \"<sos> t√¥i y√™u b·∫°n\"\n",
    "input_vi = torch.tensor([[0, 2, 3, 4]], dtype=torch.long)  # Batch size = 1\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(input_en, input_vi)\n",
    "print(\"Output shape:\", outputs.shape)  # (batch_size, trg_len, vocab_size_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted sequence: [2, 3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# üîπ Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "        # G√°n tr·ªçng s·ªë Encoder RNN & Embedding\n",
    "        with torch.no_grad():\n",
    "            self.embedding.weight.copy_(torch.tensor([\n",
    "                [1.9, 0.0],  # <eos>  (Index 0)\n",
    "                [-2.1, 0.5],  # I      (Index 1)\n",
    "                [-0.8, -1.0],  # love   (Index 2)\n",
    "                [0.2, 0.6]   # you    (Index 3)\n",
    "            ], dtype=torch.float))\n",
    "\n",
    "            self.rnn.weight_ih_l0.copy_(torch.tensor(\n",
    "                [[0.5, 0.1], [-0.1, -0.2], [0.6, 0.2]]))\n",
    "            self.rnn.bias_ih_l0.copy_(torch.tensor([0.8, -0.3, 0.1]))\n",
    "\n",
    "            self.rnn.weight_hh_l0.copy_(torch.tensor(\n",
    "                [[0.1, 0.2, 0.2], [0.2, 0.4, -0.5], [-0.1, -0.5, 0.0]]))\n",
    "            self.rnn.bias_hh_l0.copy_(torch.tensor([-0.1, -0.5, 0.0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return outputs, hidden  # `hidden` l√† hidden state cu·ªëi c√πng\n",
    "\n",
    "\n",
    "# üîπ Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)  # Softmax ƒë·ªÉ l·∫•y x√°c su·∫•t t·ª´ logits\n",
    "\n",
    "        # G√°n tr·ªçng s·ªë Decoder RNN & Embedding\n",
    "        with torch.no_grad():\n",
    "            self.embedding.weight.copy_(torch.tensor([\n",
    "                [-2.7, 1.4],  # <sos>  (Index 0)\n",
    "                [0.1, 0.0],  # <eos>  (Index 1)\n",
    "                [1.5, 0.2],  # t√¥i    (Index 2)\n",
    "                [2.2, -2.8],  # y√™u    (Index 3)\n",
    "                [-1.3, 0.1],  # b·∫°n    (Index 4)\n",
    "                [1.0, -0.5],  # anh    (Index 5)\n",
    "                [0.0, 0.0]   # em     (Index 6)\n",
    "            ], dtype=torch.float))\n",
    "\n",
    "            self.rnn.weight_ih_l0.copy_(torch.tensor(\n",
    "                [[-0.7, 0.4], [-0.3, 0.9], [0.6, -0.9]]))\n",
    "            self.rnn.bias_ih_l0.copy_(torch.tensor([0.0, 1.0, 1.1]))\n",
    "\n",
    "            self.rnn.weight_hh_l0.copy_(torch.tensor(\n",
    "                [[-0.1, -0.5, 0.8], [0.6, 0.0, -0.3], [-1.2, 0.0, 0.0]]))\n",
    "            self.rnn.bias_hh_l0.copy_(torch.tensor([-0.1, 0.5, 0.6]))\n",
    "\n",
    "            # G√°n tr·ªçng s·ªë Fully Connected\n",
    "            self.fc.weight.copy_(torch.tensor([\n",
    "                [0.2, -0.9, -0.4], [0.7, 0.7, 0.9], [0.7, 0.9, -1.4],\n",
    "                [-1.3, 1.2, 0.7], [-1.2, -1.3, 1.0], [0.4, -1.1, -0.7],\n",
    "                [-0.3, -0.6, -1.0]\n",
    "            ]))\n",
    "\n",
    "            self.fc.bias.copy_(torch.tensor(\n",
    "                [-1.1, 0.6, 0.5, 0.4, 0.4, -1.0, 0.0]))\n",
    "\n",
    "    def forward(self, x, hidden, max_len=10):\n",
    "        outputs = []\n",
    "        dec_input = x\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            embedded = self.embedding(dec_input).unsqueeze(\n",
    "                1)  # (batch, 1, embedding_dim)\n",
    "            # (batch, 1, hidden_size)\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "\n",
    "            logits = self.fc(output.squeeze(1))  # (batch, vocab_size)\n",
    "            probs = self.softmax(logits)  # X√°c su·∫•t c·ªßa t·ª´ng token\n",
    "            # Ch·ªçn token c√≥ x√°c su·∫•t cao nh·∫•t\n",
    "            predicted_token = probs.argmax(1)\n",
    "\n",
    "            outputs.append(predicted_token.item())  # L∆∞u k·∫øt qu·∫£\n",
    "            dec_input = predicted_token  # Token ti·∫øp theo l√†m input\n",
    "\n",
    "            if predicted_token.item() == 1:  # G·∫∑p <eos>, d·ª´ng l·∫°i\n",
    "                break\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "# üîπ Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        _, hidden = self.encoder(src)  # Nh·∫≠n hidden state cu·ªëi t·ª´ encoder\n",
    "        dec_input = trg[:, 0]  # Token <sos>\n",
    "        # D√πng hidden ƒë·ªÉ kh·ªüi t·∫°o decoder\n",
    "        outputs, _ = self.decoder(dec_input, hidden)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# üîπ Kh·ªüi t·∫°o m√¥ h√¨nh & D·ªØ li·ªáu\n",
    "# =====================================\n",
    "vocab_size_en = 4  # S·ªë t·ª´ trong vocab ti·∫øng Anh\n",
    "vocab_size_vi = 7  # S·ªë t·ª´ trong vocab ti·∫øng Vi·ªát\n",
    "embedding_dim = 2\n",
    "hidden_size = 3\n",
    "\n",
    "encoder = Encoder(vocab_size_en, embedding_dim, hidden_size)\n",
    "decoder = Decoder(vocab_size_vi, embedding_dim, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "# üîπ C√¢u ti·∫øng Anh: \"I love you <eos>\"\n",
    "input_en = torch.tensor([[1, 2, 3, 0]], dtype=torch.long)  # Batch size = 1\n",
    "# üîπ C√¢u ti·∫øng Vi·ªát: \"<sos>\"\n",
    "# Batch size = 1, b·∫Øt ƒë·∫ßu v·ªõi <sos>\n",
    "input_vi = torch.tensor([[0]], dtype=torch.long)\n",
    "\n",
    "# Forward pass\n",
    "output_tokens = model(input_en, input_vi)\n",
    "print(\"\\nPredicted sequence:\", output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.]]]], grad_fn=<ConvolutionBackward0>)\n",
      "\n",
      "Input Shape: torch.Size([1, 1, 4, 4])\n",
      "Output Shape: torch.Size([1, 1, 4, 4])\n",
      "Output Tensor:\n",
      " tensor([[[[41., 61., 60., 40.],\n",
      "          [61., 91., 90., 60.],\n",
      "          [60., 90., 91., 61.],\n",
      "          [40., 60., 61., 41.]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        # üîπ Encoder\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3,\n",
    "                               padding=1, stride=1, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1, 1, kernel_size=3,\n",
    "                               padding=1, stride=1, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # üîπ Bottleneck\n",
    "        self.bottleneck = nn.Conv2d(\n",
    "            1, 1, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "\n",
    "        # üîπ Decoder\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv3 = nn.Conv2d(1, 1, kernel_size=3,\n",
    "                               padding=1, stride=1, bias=False)\n",
    "\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv4 = nn.Conv2d(1, 1, kernel_size=3,\n",
    "                               padding=1, stride=1, bias=False)\n",
    "\n",
    "        # üîπ Kh·ªüi t·∫°o tr·ªçng s·ªë = 1 (theo y√™u c·∫ßu)\n",
    "        with torch.no_grad():\n",
    "            for layer in [self.conv1, self.conv2, self.bottleneck, self.conv3, self.conv4]:\n",
    "                layer.weight.fill_(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # üîπ Encoder\n",
    "        x1 = self.conv1(x)  # Conv1\n",
    "        x1 = self.pool1(x1)  # MaxPooling1 (4x4 ‚Üí 2x2)\n",
    "\n",
    "        x2 = self.conv2(x1)  # Conv2\n",
    "        x2 = self.pool2(x2)  # MaxPooling2 (2x2 ‚Üí 1x1)\n",
    "\n",
    "        # üîπ Bottleneck\n",
    "        x_b = self.bottleneck(x2)  # (1x1 ‚Üí 1x1)\n",
    "        print(x_b)\n",
    "        # üîπ Decoder\n",
    "        x3 = self.upsample1(x_b)  # Upsampling1 (1x1 ‚Üí 2x2)\n",
    "        x3 = self.conv3(x3)\n",
    "\n",
    "        # ‚úÖ C·∫ßn ƒëi·ªÅu ch·ªânh x2 ƒë·ªÉ c√πng k√≠ch th∆∞·ªõc v·ªõi x3\n",
    "        x3 = x3 + F.interpolate(x2, scale_factor=2,\n",
    "                                mode='nearest')  # Skip Connection 1\n",
    "\n",
    "        x4 = self.upsample2(x3)  # Upsampling2 (2x2 ‚Üí 4x4)\n",
    "        x4 = self.conv4(x4)\n",
    "\n",
    "        # ‚úÖ C·∫ßn ƒëi·ªÅu ch·ªânh x1 ƒë·ªÉ c√πng k√≠ch th∆∞·ªõc v·ªõi x4\n",
    "        x4 = x4 + F.interpolate(x1, scale_factor=2,\n",
    "                                mode='nearest')  # Skip Connection 2\n",
    "\n",
    "        return x4\n",
    "\n",
    "\n",
    "# üîπ Ki·ªÉm th·ª≠ m√¥ h√¨nh\n",
    "model = SimpleUNet()\n",
    "input_tensor = torch.tensor([[[[1, 0, 0, 0],\n",
    "                               [0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0],\n",
    "                               [0, 0, 0, 1]]]], dtype=torch.float)\n",
    "\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(\"\\nInput Shape:\", input_tensor.shape)\n",
    "print(\"Output Shape:\", output.shape)  # (1, 1, 4, 4)\n",
    "print(\"Output Tensor:\\n\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIOEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
