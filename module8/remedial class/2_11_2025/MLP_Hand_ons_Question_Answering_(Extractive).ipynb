{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.17.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "78IoPbnBLRLw",
        "outputId": "48792337-a239-4968-a235-271847bf43fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.17.0\n",
            "  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n",
            "Collecting torch==2.2.0 (from torchtext==0.17.0)\n",
            "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.4)\n",
            "Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n",
            "  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
            "Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "oQ7JCYWOKubQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "CrjBpUE3KLxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset = [\n",
        "    {\n",
        "        \"context\": \"Albert Einstein is very smart\",\n",
        "        \"question\": \"Who is very smart\",\n",
        "        \"answer\": \"Albert Einstein\",\n",
        "        \"start_token\": 0,\n",
        "        \"end_token\": 1\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"The forest cover over three thousand hectares\",\n",
        "        \"question\": \"How much forest cover\",\n",
        "        \"answer\": \"over three thousand hectares\",\n",
        "        \"start_token\": 3,\n",
        "        \"end_token\": 6\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "J7d4yWeUKNET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in qa_dataset:\n",
        "    print(f\"Context: {sample['context']}\")\n",
        "    print(f\"Question: {sample['question']}\")\n",
        "    print(f\"Answer: {sample['answer']} (Start: {sample['start_token']}, End: {sample['end_token']})\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juYnYm2dKN3R",
        "outputId": "7f6ba404-d440-4ec7-ccce-7ab390d0417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: Albert Einstein is very smart\n",
            "Question: Who is very smart\n",
            "Answer: Albert Einstein (Start: 0, End: 1)\n",
            "--------------------------------------------------\n",
            "Context: The forest cover over three thousand hectares\n",
            "Question: How much forest cover\n",
            "Answer: over three thousand hectares (Start: 3, End: 6)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesing"
      ],
      "metadata": {
        "id": "O3UgiHDvLKSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "# Step 1: Tokenization\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "for sample in qa_dataset:\n",
        "    sample[\"context_tokens\"] = tokenizer(sample[\"context\"])\n",
        "    sample[\"question_tokens\"] = tokenizer(sample[\"question\"])\n",
        "\n",
        "print(\"-\" * 100)\n",
        "for sample in qa_dataset:\n",
        "    print(f\"Context Tokens: {sample['context_tokens']}\")\n",
        "    print(f\"Question Tokens: {sample['question_tokens']}\")\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_zgcnrlNzhX",
        "outputId": "b19b10a6-9632-410b-c2e8-d484a4704a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Context Tokens: ['albert', 'einstein', 'is', 'very', 'smart']\n",
            "Question Tokens: ['who', 'is', 'very', 'smart']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Context Tokens: ['the', 'forest', 'cover', 'over', 'three', 'thousand', 'hectares']\n",
            "Question Tokens: ['how', 'much', 'forest', 'cover']\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Build Vocabulary\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "def yield_tokens(dataset):\n",
        "    for sample in dataset:\n",
        "        yield sample[\"context_tokens\"]\n",
        "        yield sample[\"question_tokens\"]\n",
        "\n",
        "# Define vocab size\n",
        "vocab_size = 12\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(yield_tokens(qa_dataset),\n",
        "                                  max_tokens=vocab_size,\n",
        "                                  specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])  # Set unknown token index\n",
        "\n",
        "# Print vocabulary mappings\n",
        "print(\"Vocabulary Mapping:\")\n",
        "print(vocab.get_stoi())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8QLKU_ILyxS",
        "outputId": "5421a74e-1200-4b92-b116-df10d65bf85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Mapping:\n",
            "{'much': 11, 'how': 10, 'albert': 7, 'hectares': 9, 'very': 6, 'smart': 5, 'is': 4, 'forest': 3, 'cover': 2, 'einstein': 8, '<pad>': 1, '<unk>': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Vectorization\n",
        "def vectorize(tokens, vocab, sequence_length):\n",
        "    token_ids = [vocab[token] for token in tokens][:sequence_length]\n",
        "    token_ids += [vocab[\"<pad>\"]] * (sequence_length - len(token_ids))  # Pad sequence\n",
        "    return torch.tensor(token_ids, dtype=torch.long)\n",
        "\n",
        "context_length = 5\n",
        "question_length = 5\n",
        "\n",
        "for sample in qa_dataset:\n",
        "    sample[\"context_vector\"] = vectorize(sample[\"context_tokens\"], vocab, context_length)\n",
        "    sample[\"question_vector\"] = vectorize(sample[\"question_tokens\"], vocab, question_length)\n",
        "print(\"-\" * 50)\n",
        "for sample in qa_dataset:\n",
        "    print(f\"Context Vector: {sample['context_vector']}\")\n",
        "    print(f\"Question Vector: {sample['question_vector']}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siXWH63gMCPX",
        "outputId": "b082d060-a33f-4982-e403-fef9bfb88d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Context Vector: tensor([7, 8, 4, 6, 5])\n",
            "Question Vector: tensor([0, 4, 6, 5, 1])\n",
            "--------------------------------------------------\n",
            "Context Vector: tensor([0, 3, 2, 0, 0])\n",
            "Question Vector: tensor([10, 11,  3,  2,  1])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP model"
      ],
      "metadata": {
        "id": "VOZQqIYZQ3u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_length, question_length):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        input_dim = embedding_dim * (context_length + question_length)  # Combined input size\n",
        "        self.fc_start = nn.Linear(input_dim, context_length)  # Start token scores\n",
        "        self.fc_end = nn.Linear(input_dim, context_length)    # End token scores\n",
        "\n",
        "    def forward(self, context, question):\n",
        "        context_emb = self.embedding(context)  # (batch, context_len, emb_dim)\n",
        "        question_emb = self.embedding(question)  # (batch, question_len, emb_dim)\n",
        "\n",
        "        x = torch.cat([context_emb, question_emb], dim=1)  # Concatenate along token axis\n",
        "        x = self.flatten(x)  # Flatten embeddings\n",
        "\n",
        "        start_scores = self.fc_start(x)  # Predict start positions\n",
        "        end_scores = self.fc_end(x)      # Predict end positions\n",
        "        return start_scores, end_scores"
      ],
      "metadata": {
        "id": "kvnA4oAL1hqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_length, question_length):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        print(\"🟢 Embedding:\")\n",
        "        print(self.embedding.weight)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        input_dim = embedding_dim * (context_length + question_length)  # Combined input size\n",
        "        self.fc_start = nn.Linear(input_dim, context_length)  # Start token scores\n",
        "        self.fc_end = nn.Linear(input_dim, context_length)    # End token scores\n",
        "        print(\"🟢 FC Start:\")\n",
        "        print(self.fc_start.weight)\n",
        "        print(\"🟢 FC Start Bias:\")\n",
        "        print(self.fc_start.bias)\n",
        "        print(\"🟢 FC End:\")\n",
        "        print(self.fc_end.weight)\n",
        "        print(\"🟢 FC End Bias:\")\n",
        "        print(self.fc_end.bias)\n",
        "\n",
        "    def forward(self, context, question):\n",
        "        print(\"🟢 Context:\")\n",
        "        print(context)\n",
        "        print(\"🟠 Question:\")\n",
        "        print(question)\n",
        "\n",
        "        context_emb = self.embedding(context)  # (batch, context_len, emb_dim)\n",
        "        question_emb = self.embedding(question)  # (batch, question_len, emb_dim)\n",
        "\n",
        "        print(\"🟢 Context Embedding:\")\n",
        "        print(context_emb)\n",
        "        print(\"🟠 Question Embedding:\")\n",
        "        print(question_emb)\n",
        "\n",
        "        x = torch.cat([question_emb, context_emb], dim=1)  # Concatenate along token axis\n",
        "        print(\"🔵 Concatenated Embedding:\")\n",
        "        print(x)\n",
        "\n",
        "        x = self.flatten(x)  # Flatten embeddings\n",
        "        print(\"🟣 Flattened Input:\")\n",
        "        print(x)\n",
        "\n",
        "        start_scores = self.fc_start(x)  # Predict start positions\n",
        "        end_scores = self.fc_end(x)      # Predict end positions\n",
        "\n",
        "\n",
        "        print(\"🔴 Start Scores:\")\n",
        "        print(start_scores)\n",
        "        print(\"🔵 End Scores:\")\n",
        "        print(end_scores)\n",
        "\n",
        "\n",
        "        return start_scores, end_scores"
      ],
      "metadata": {
        "id": "bEh_doo9Q0fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 2\n",
        "model = SimpleMLP(vocab_size, embedding_dim, context_length, question_length)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "4QpacoxgMCWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0d1a7d-cf7a-44bd-a1a5-b96e1383765d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 Embedding:\n",
            "Parameter containing:\n",
            "tensor([[ 1.9269,  1.4873],\n",
            "        [ 0.9007, -2.1055],\n",
            "        [ 0.6784, -1.2345],\n",
            "        [-0.0431, -1.6047],\n",
            "        [ 0.3559, -0.6866],\n",
            "        [-0.4934,  0.2415],\n",
            "        [-1.1109,  0.0915],\n",
            "        [-2.3169, -0.2168],\n",
            "        [-0.3097, -0.3957],\n",
            "        [ 0.8034, -0.6216],\n",
            "        [-0.5920, -0.0631],\n",
            "        [-0.8286,  0.3309]], requires_grad=True)\n",
            "🟢 FC Start:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0601, -0.0606,  0.0941,  0.1996,  0.1293, -0.0978,  0.1291,  0.0400,\n",
            "          0.1136, -0.1363, -0.2214, -0.0864, -0.1715,  0.1835,  0.0644,  0.0926,\n",
            "          0.0707, -0.0039,  0.1750, -0.1589],\n",
            "        [ 0.0141, -0.1526,  0.0689, -0.0770,  0.0685, -0.0466,  0.1855, -0.1325,\n",
            "         -0.1334, -0.1334,  0.2011,  0.0745,  0.2152, -0.1845, -0.2218, -0.1749,\n",
            "         -0.1504,  0.0906,  0.0801,  0.1858],\n",
            "        [-0.1155, -0.1524,  0.1186, -0.0904,  0.1357, -0.0531,  0.1279, -0.1737,\n",
            "         -0.1128,  0.0682,  0.0473, -0.0570,  0.1333,  0.1520, -0.1622, -0.1194,\n",
            "          0.2047, -0.0755, -0.0793, -0.2164],\n",
            "        [-0.1281,  0.0559, -0.0295, -0.1623,  0.0052, -0.1527, -0.1897, -0.1231,\n",
            "         -0.1957, -0.1424,  0.2235,  0.0422,  0.0689, -0.2086, -0.1469, -0.0744,\n",
            "          0.0350, -0.1968, -0.0963, -0.1339],\n",
            "        [ 0.0006, -0.0832, -0.0155, -0.1515, -0.1535, -0.1305, -0.0765, -0.1765,\n",
            "          0.1875, -0.0444,  0.1924,  0.0697, -0.1893,  0.1547, -0.0615, -0.0857,\n",
            "         -0.1856, -0.2223,  0.0640, -0.0488]], requires_grad=True)\n",
            "🟢 FC Start Bias:\n",
            "Parameter containing:\n",
            "tensor([ 0.0871, -0.1835,  0.1660, -0.1641, -0.0386], requires_grad=True)\n",
            "🟢 FC End:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0467,  0.1154,  0.1805,  0.2037, -0.1773,  0.0563, -0.0962, -0.0245,\n",
            "         -0.1674,  0.2037, -0.1641,  0.1195,  0.0786,  0.0727, -0.1209,  0.2032,\n",
            "          0.0491,  0.0288, -0.1971,  0.0939],\n",
            "        [-0.0335, -0.1024,  0.1921,  0.0499, -0.1237, -0.1132, -0.0107,  0.1249,\n",
            "         -0.0571, -0.1276, -0.0766, -0.1671,  0.0797,  0.1731, -0.2105,  0.0519,\n",
            "          0.1155,  0.0405, -0.0796,  0.1167],\n",
            "        [ 0.1175,  0.0836, -0.0393, -0.0592,  0.0239, -0.0395, -0.0666,  0.1429,\n",
            "          0.1922, -0.0221, -0.0501,  0.0033, -0.0134,  0.0538,  0.0627, -0.2031,\n",
            "         -0.0825,  0.1883,  0.0871, -0.0111],\n",
            "        [-0.1348, -0.1368, -0.2003, -0.0729,  0.0755,  0.1426,  0.1032, -0.1977,\n",
            "         -0.1345, -0.0353,  0.2163,  0.0323, -0.0579,  0.0925, -0.0852, -0.1447,\n",
            "          0.1632, -0.1017, -0.0448, -0.2224],\n",
            "        [ 0.1497,  0.1694,  0.0815, -0.1559, -0.2207, -0.1816,  0.1667,  0.1074,\n",
            "          0.1882,  0.1171,  0.0566, -0.0022, -0.1701, -0.1916, -0.2092,  0.0915,\n",
            "         -0.1098, -0.0450, -0.1287, -0.0407]], requires_grad=True)\n",
            "🟢 FC End Bias:\n",
            "Parameter containing:\n",
            "tensor([-0.1574, -0.1461,  0.0742, -0.0665,  0.1380], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels (start & end) to tensor\n",
        "def get_labels(sample):\n",
        "    return torch.tensor([sample[\"start_token\"], sample[\"end_token\"]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "KBbwrHkoTbwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.embedding.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "Z9U18lhD_mj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for sample in qa_dataset:\n",
        "        context_vector = sample[\"context_vector\"].unsqueeze(0)  # Add batch dim\n",
        "        question_vector = sample[\"question_vector\"].unsqueeze(0)  # Add batch dim\n",
        "        start_label, end_label = get_labels(sample)\n",
        "        print(f\"🔵 Start Label: {start_label}\")\n",
        "        print(f\"🟣 End Label: {end_label}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        start_scores, end_scores = model(context_vector, question_vector)\n",
        "\n",
        "        loss_start = loss_fn(start_scores.float(), start_label.unsqueeze(0).long())\n",
        "        loss_end = loss_fn(end_scores.float(), end_label.unsqueeze(0).long())\n",
        "\n",
        "        loss = loss_start + loss_end  # Combine both losses\n",
        "\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if epoch == 0:\n",
        "        print(f\"📈 Epoch {epoch}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9DoOTgXDK_DG",
        "outputId": "d1c7b600-5d7e-42fd-e889-ad8b6af56580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔵 Start Label: 0.0\n",
            "🟣 End Label: 1.0\n",
            "🟢 Context:\n",
            "tensor([[7, 8, 4, 6, 5]])\n",
            "🟠 Question:\n",
            "tensor([[0, 4, 6, 5, 1]])\n",
            "🟢 Context Embedding:\n",
            "tensor([[[-2.3169, -0.2168],\n",
            "         [-0.3097, -0.3957],\n",
            "         [ 0.3559, -0.6866],\n",
            "         [-1.1109,  0.0915],\n",
            "         [-0.4934,  0.2415]]])\n",
            "🟠 Question Embedding:\n",
            "tensor([[[ 1.9269,  1.4873],\n",
            "         [ 0.3559, -0.6866],\n",
            "         [-1.1109,  0.0915],\n",
            "         [-0.4934,  0.2415],\n",
            "         [ 0.9007, -2.1055]]])\n",
            "🔵 Concatenated Embedding:\n",
            "tensor([[[ 1.9269,  1.4873],\n",
            "         [ 0.3559, -0.6866],\n",
            "         [-1.1109,  0.0915],\n",
            "         [-0.4934,  0.2415],\n",
            "         [ 0.9007, -2.1055],\n",
            "         [-2.3169, -0.2168],\n",
            "         [-0.3097, -0.3957],\n",
            "         [ 0.3559, -0.6866],\n",
            "         [-1.1109,  0.0915],\n",
            "         [-0.4934,  0.2415]]])\n",
            "🟣 Flattened Input:\n",
            "tensor([[ 1.9269,  1.4873,  0.3559, -0.6866, -1.1109,  0.0915, -0.4934,  0.2415,\n",
            "          0.9007, -2.1055, -2.3169, -0.2168, -0.3097, -0.3957,  0.3559, -0.6866,\n",
            "         -1.1109,  0.0915, -0.4934,  0.2415]])\n",
            "🔴 Start Scores:\n",
            "tensor([[ 0.4595, -0.6030, -1.1066, -0.5680,  0.0694]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "🔵 End Scores:\n",
            "tensor([[-0.1207,  0.0034,  1.0317, -1.4472,  0.9415]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "🔵 Start Label: 3.0\n",
            "🟣 End Label: 6.0\n",
            "🟢 Context:\n",
            "tensor([[0, 3, 2, 0, 0]])\n",
            "🟠 Question:\n",
            "tensor([[10, 11,  3,  2,  1]])\n",
            "🟢 Context Embedding:\n",
            "tensor([[[ 1.9269,  1.4873],\n",
            "         [-0.0431, -1.6047],\n",
            "         [ 0.6784, -1.2345],\n",
            "         [ 1.9269,  1.4873],\n",
            "         [ 1.9269,  1.4873]]])\n",
            "🟠 Question Embedding:\n",
            "tensor([[[-0.5920, -0.0631],\n",
            "         [-0.8286,  0.3309],\n",
            "         [-0.0431, -1.6047],\n",
            "         [ 0.6784, -1.2345],\n",
            "         [ 0.9007, -2.1055]]])\n",
            "🔵 Concatenated Embedding:\n",
            "tensor([[[-0.5920, -0.0631],\n",
            "         [-0.8286,  0.3309],\n",
            "         [-0.0431, -1.6047],\n",
            "         [ 0.6784, -1.2345],\n",
            "         [ 0.9007, -2.1055],\n",
            "         [ 1.9269,  1.4873],\n",
            "         [-0.0431, -1.6047],\n",
            "         [ 0.6784, -1.2345],\n",
            "         [ 1.9269,  1.4873],\n",
            "         [ 1.9269,  1.4873]]])\n",
            "🟣 Flattened Input:\n",
            "tensor([[-0.5920, -0.0631, -0.8286,  0.3309, -0.0431, -1.6047,  0.6784, -1.2345,\n",
            "          0.9007, -2.1055,  1.9269,  1.4873, -0.0431, -1.6047,  0.6784, -1.2345,\n",
            "          1.9269,  1.4873,  1.9269,  1.4873]])\n",
            "🔴 Start Scores:\n",
            "tensor([[-0.0592,  1.3833, -0.1471,  0.4780,  0.2338]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "🔵 End Scores:\n",
            "tensor([[-1.6658, -0.6008,  0.4610,  0.3849, -0.2974]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Target 6 is out of bounds.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2e5e693fa305>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_end\u001b[0m  \u001b[0;31m# Combine both losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 6 is out of bounds."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "a = [ 0.4595, -0.6030, -1.1066, -0.5680,  0.0694]\n",
        "b = [-0.1207,  0.0034,  1.0317, -1.4472,  0.9415]\n",
        "\n",
        "rsa = []\n",
        "rsb = []\n",
        "for x in a:\n",
        "    rsa.append(round(math.e**x, 4))\n",
        "for x in b:\n",
        "    rsb.append(round(math.e**x, 4))\n",
        "\n",
        "print(\"a: \" + str(rsa))\n",
        "print(sum(rsa))\n",
        "print(\"b: \" + str(rsb))\n",
        "print(sum(rsb))\n",
        "\n",
        "softmaxa = []\n",
        "softmaxb = []\n",
        "for x in rsa:\n",
        "    softmaxa.append(round(x/sum(rsa), 4))\n",
        "for x in rsb:\n",
        "    softmaxb.append(round(x/sum(rsb), 4))\n",
        "\n",
        "print(\"a: \" + str(softmaxa))\n",
        "print(\"b: \" + str(softmaxb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3y4T7F8hmU5",
        "outputId": "576986b6-bd54-401a-ccb7-efac9d954780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: [1.5833, 0.5472, 0.3307, 0.5667, 1.0719]\n",
            "4.0998\n",
            "b: [0.8863, 1.0034, 2.8058, 0.2352, 2.5638]\n",
            "7.4945\n",
            "a: [0.3862, 0.1335, 0.0807, 0.1382, 0.2615]\n",
            "b: [0.1183, 0.1339, 0.3744, 0.0314, 0.3421]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "17RRgfuGhmp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Illustrate"
      ],
      "metadata": {
        "id": "SzoO3LeMT-Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_scores(context, question, model, vocab, context_length):\n",
        "    \"\"\"Visualize start and end token scores.\"\"\"\n",
        "    context_tokens = tokenizer(context)\n",
        "    question_tokens = tokenizer(question)\n",
        "\n",
        "    context_vector = vectorize(context_tokens, vocab, context_length).unsqueeze(0)\n",
        "    question_vector = vectorize(question_tokens, vocab, question_length).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_scores, end_scores = model(context_vector, question_vector)\n",
        "        start_scores = start_scores.squeeze().numpy()\n",
        "        end_scores = end_scores.squeeze().numpy()\n",
        "\n",
        "    token_labels = [f\"{i}\" for i in range(len(start_scores))]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.bar(range(len(start_scores)), start_scores, color=\"blue\", alpha=0.7)\n",
        "    plt.xticks(range(len(start_scores)), token_labels, rotation=45, ha=\"right\")\n",
        "    plt.title(\"Start Token Scores\")\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.bar(range(len(end_scores)), end_scores, color=\"red\", alpha=0.7)\n",
        "    plt.xticks(range(len(end_scores)), token_labels, rotation=45, ha=\"right\")\n",
        "    plt.title(\"End Token Scores\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DxvEgehhSn7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = qa_dataset[0][\"context\"]\n",
        "question = qa_dataset[0][\"question\"]\n",
        "visualize_scores(context, question, model, vocab, context_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "V-9teqbvVFfr",
        "outputId": "fadb3f6c-7c3f-402e-b860-e52fcfff0352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = qa_dataset[1][\"context\"]\n",
        "question = qa_dataset[1][\"question\"]\n",
        "visualize_scores(context, question, model, vocab, context_length)"
      ],
      "metadata": {
        "id": "XzwdqDq0Z5Kh",
        "outputId": "10cf666d-12f7-4f0c-def4-2f9bb23531ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = qa_dataset[0]\n",
        "context_vector = sample[\"context_vector\"].unsqueeze(0)  # Add batch dimension\n",
        "question_vector = sample[\"question_vector\"].unsqueeze(0)  # Add batch dimension"
      ],
      "metadata": {
        "id": "x35ZlkcMcdWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    print(f\"\\n Running Inference for Question: {sample['question']}\\n\")\n",
        "    start_scores, end_scores = model(context_vector, question_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OEIqhmLciJm",
        "outputId": "9d89606d-161f-40c8-d9de-9f8b9fbb5e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Running Inference for Question: Who is very smart?\n",
            "\n",
            "🟢 Context Embedding:\n",
            "tensor([[[ 0.8466, -1.4241],\n",
            "         [-1.1002,  1.2863],\n",
            "         [-1.4863,  0.3034],\n",
            "         [-0.3233,  1.8174],\n",
            "         [-0.7436, -1.1663],\n",
            "         [-0.2292, -0.8918],\n",
            "         [ 0.8830,  0.6806]]])\n",
            "🟠 Question Embedding:\n",
            "tensor([[[-0.0535, -1.5092],\n",
            "         [-1.4863,  0.3034],\n",
            "         [-0.3233,  1.8174],\n",
            "         [-0.7436, -1.1663],\n",
            "         [ 0.3303, -1.5258]]])\n",
            "🔵 Concatenated Embedding:\n",
            "tensor([[[ 0.8466, -1.4241],\n",
            "         [-1.1002,  1.2863],\n",
            "         [-1.4863,  0.3034],\n",
            "         [-0.3233,  1.8174],\n",
            "         [-0.7436, -1.1663],\n",
            "         [-0.2292, -0.8918],\n",
            "         [ 0.8830,  0.6806],\n",
            "         [-0.0535, -1.5092],\n",
            "         [-1.4863,  0.3034],\n",
            "         [-0.3233,  1.8174],\n",
            "         [-0.7436, -1.1663],\n",
            "         [ 0.3303, -1.5258]]])\n",
            "🟣 Flattened Input:\n",
            "tensor([[ 0.8466, -1.4241, -1.1002,  1.2863, -1.4863,  0.3034, -0.3233,  1.8174,\n",
            "         -0.7436, -1.1663, -0.2292, -0.8918,  0.8830,  0.6806, -0.0535, -1.5092,\n",
            "         -1.4863,  0.3034, -0.3233,  1.8174, -0.7436, -1.1663,  0.3303, -1.5258]])\n",
            "🔴 Start Scores:\n",
            "tensor([[-0.3615, -0.7290, -0.5528,  0.1551, -0.3587,  0.4424,  0.6114]])\n",
            "🔵 End Scores:\n",
            "tensor([[-0.3896, -0.1513, -0.2591, -0.8606,  0.9907,  0.2735,  0.8404]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_start = torch.argmax(start_scores, dim=1).item()\n",
        "predicted_end = torch.argmax(end_scores, dim=1).item()\n",
        "print(f\"Predicted Start Token Index: {predicted_start}\")\n",
        "print(f\"Predicted End Token Index: {predicted_end}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfAr5WAzcj-l",
        "outputId": "e8f32dfc-a75b-44f0-bb33-33247ecd2b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Start Token Index: 6\n",
            "Predicted End Token Index: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample[\"context_tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBrVkUbsc3r-",
        "outputId": "71554ff5-8de1-478d-f2cd-5b960ee8d6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['albert', 'einstein', 'is', 'very', 'smart', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_answer_tokens = sample[\"context_tokens\"][predicted_start : predicted_end + 1]\n",
        "predicted_answer_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OEWd615c5qG",
        "outputId": "dd1ee790-109b-4182-e920-83a56f5b743e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_answer = \" \".join(predicted_answer_tokens)\n",
        "predicted_answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6kbmediYc91W",
        "outputId": "9d9bf3e0-739d-4665-dde7-f72fff1542db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The problem is how can we deal with the end_token < the start_token during training**"
      ],
      "metadata": {
        "id": "g2u2FH8_dkby"
      }
    }
  ]
}